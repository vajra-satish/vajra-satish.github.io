[
  {
    "objectID": "reports/Transitioning from informality to formality - Perspectives on formalization of informal enterprises/index.html",
    "href": "reports/Transitioning from informality to formality - Perspectives on formalization of informal enterprises/index.html",
    "title": "Transitioning from informality to formality: Perspectives on formalization of informal enterprises",
    "section": "",
    "text": "Abstract: The informal economy is a common feature of developing countries and Nepal is no exception to it. Addressing the issue of heterogeneity is imperative to understanding informal enterprises, as one policy solution that works for some informal enterprises might not work for other informal enterprises. In a similar vein, the impact of the Covid-19 on informal enterprises is also an important issue that needs to be addressed. Additionally, the workers in the informal economy face rights, social protection, and representational deficits. Literature suggests three important policy implications to deal with informality: reduction of tax rates and entry costs, strict law enforcement, and improved business environment. In essence, it is crucial to understand if these policy implications are applicable in the context of Nepal. In this study, primary and secondary sources of data have been used. Inferential statistical analysis is done from the World Bank Enterprise Survey data and the World Bank Informal Survey data to make generalizations about the population of informal enterprises in Nepal. Likewise, qualitative content analysis is done from the personal interview survey data to understand enterprises from a closer perspective. The research provides some important insights on informality in the context of Nepal: a) registration depends upon important factors such as the age of the owner, sales, market speculation, business maturity, level of law enforcement, business environment, strategic behavior of competitors, and market conditions, b) the associated costs of registration is higher than its benefits, c) informal enterprises are flexible and they tend to depend on informal sources of finance, d) informal enterprises are vulnerable to external shocks like the Covid-19 pandemic. The research concludes on the need to adopt a synergistic policy approach, whereby emphasis should be laid on building a centralized database for informal workers, better access to finance, distinguished policy options for informal enterprises, information campaigns on registration procedures and benefits to registration, long-term policy on economic growth and accessible education, flexible and market-oriented training programs, identification of intermediaries, working through intermediaries to provide selective benefits and a mechanism to provide a safety net for informal workers and own-account informal workers."
  },
  {
    "objectID": "publications.html",
    "href": "publications.html",
    "title": "Satish Bajracharya",
    "section": "",
    "text": "Transitioning from informality to formality: Perspectives on formalization of informal enterprises\n\n\n\n\n\n\n\npublished report\n\n\n\n\n\n\n\n\n\n\n\nDec 22, 2021\n\n\nSatish Bajracharya, Daayitwa Nepal Public Policy Fellow\n\n\n\n\n\n\n  \n\n\n\n\nBreaking down the culture of change\n\n\n\n\n\n\n\npublished blog\n\n\n\n\n\n\n\n\n\n\n\nNov 10, 2021\n\n\nSatish Bajracharya, Daayitwa Nepal Public Policy Fellow\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/Power Calculations Using Stata - Unclustered RCT/index.html#multiple-effect-size-calculation",
    "href": "posts/Power Calculations Using Stata - Unclustered RCT/index.html#multiple-effect-size-calculation",
    "title": "Power Calculations Using Stata: Unclustered RCT",
    "section": "Multiple effect size calculation",
    "text": "Multiple effect size calculation\nExecution in R\nTo calculate the sample size required for the treatment effects (0.01, 0.025, 0.05, 0.1, 0.2), we can use the for function to iterate the effect sizes and use the pwr.t.test function to calculate the corresponding sample size.\n\n# Create variable effect_sizes and assign the treatment effects\neffect_sizes &lt;- c(0.01, 0.025, 0.05, 0.1, 0.2)\n# Initialize an empty dataframe to store the results\nresult_table &lt;- data.frame()\n# Iterate over each effect size\nfor (i in effect_sizes) {\n# Calculate sample size using the pwr.t.test function\n# Make sure that the pwr package is loaded in R\nresult &lt;- pwr.t.test(n = NULL,\n                     d = i, \n                     sig.level = 0.05,\n                     power = 0.8,\n                     type = \"two.sample\")\n# n gives the sample size for each group\n# Multiply by 2 to gett the total sample size\nsample_size &lt;- result$n*2\n# Sample size for control group\nN1 &lt;- sample_size\n# Sample size for treatment group\nN2 &lt;- sample_size\n# Test size\nalpha &lt;- result$sig.level\n# Power\npower &lt;- result$power\n# Effect size\ndelta &lt;- result$d\n# Control group mean\nm1 &lt;- 0\n# Treatment group mean\nm2 &lt;- result$d\n# Standard deviation\nStd_dev&lt;- 1\n# Append the results to the dataframe\nresult_table &lt;- rbind(result_table,\n                      c(alpha, \n                        power,\n                        sample_size,\n                        N1, \n                        N2, \n                        delta,\n                        m1, \n                        m2, \n                        Std_dev))\n}\n# Assign column names\ncolnames(result_table) &lt;- c(\"Alpha\",\n                            \"Power\",\n                            \"Sample size\", \n                            \"N1\", \n                            \"N2\", \n                            \"Delta\", \n                            \"M1\", \n                            \"M2\", \n                            \"Std.Dev\")\n# Print the result table\nprint(result_table)\n\n  Alpha Power Sample size          N1          N2 Delta M1    M2 Std.Dev\n1  0.05   0.8 313956.3412 313956.3412 313956.3412 0.010  0 0.010       1\n2  0.05   0.8  50234.6281  50234.6281  50234.6281 0.025  0 0.025       1\n3  0.05   0.8  12560.0979  12560.0979  12560.0979 0.050  0 0.050       1\n4  0.05   0.8   3141.4661   3141.4661   3141.4661 0.100  0 0.100       1\n5  0.05   0.8    786.8114    786.8114    786.8114 0.200  0 0.200       1\n\n\nExecution in Stata\nWe again use the power twomeans command in Stata to calculate the respective sample size for the given effect size. The option table(, labels(N “Sample size” sd “Std. Dev”)) indicates that we want the output in table format, and that we want “N” to be renamed as “Sample size and sd to be renamed as”Std. Dev”.\n\npower twomeans 0 (0.01 0.025 0.05 0.1 0.2), table(, labels(N \"Sample size\" sd \"Std. Dev.\"))\n\n\n\n. power twomeans 0 (0.01 0.025 0.05 0.1 0.2), table(, labels(N \"Sample size\" sd\n&gt;  \"Std. Dev.\"))\n\nPerforming iteration Estimated sample sizes for a two-sample means test\nt test assuming sd1 = sd2 = sd\nHo: m2 = m1  versus  Ha: m2 != m1\n\n  +---------------------------------------------------------------------+\n  |   alpha   power Sample size      N1      N2   delta      m1      m2 |\n  |---------------------------------------------------------------------|\n  |     .05      .8     3.1e+05 1.6e+05 1.6e+05     .01       0     .01 |\n  |     .05      .8       50236   25118   25118    .025       0    .025 |\n  |     .05      .8       12562   6,281   6,281     .05       0     .05 |\n  |     .05      .8       3,142   1,571   1,571      .1       0      .1 |\n  |     .05      .8         788     394     394      .2       0      .2 |\n  +---------------------------------------------------------------------+\n  +-----------+\n  | Std. Dev. |\n  |-----------|\n  |         1 |\n  |         1 |\n  |         1 |\n  |         1 |\n  |         1 |\n  +-----------+\n\n\nWe can see that the required sample size increases exponentially as the effect size approaches 0. Instead of a table calculations might be easier to interpret in a graph."
  },
  {
    "objectID": "posts/Power Calculations Using Stata - Unclustered RCT/index.html#plotting-the-relationship",
    "href": "posts/Power Calculations Using Stata - Unclustered RCT/index.html#plotting-the-relationship",
    "title": "Power Calculations Using Stata: Unclustered RCT",
    "section": "Plotting the relationship",
    "text": "Plotting the relationship\nExecution in R\n\n# Load the grammar of graphics package to plot the graph\nlibrary(ggplot2)\n# Load dplyr package to use pipe operator |&gt; to enter commands in a chain\nlibrary(dplyr)\nresult_table |&gt; # select variables Delta and Sample size from the data frame \n  select(Delta, `Sample size`) |&gt;\n  ggplot(aes( x = Delta, y = `Sample size`)) + # plot Delta on the x-axis\n  # and Sample size on the y-axis\n  geom_line(color = \"#2c3e50\", lwd = 1) + # add a geometric line to the plot \n  geom_point(color = \"#2c3e50\", size = 2) + # add a geometric point to the plot \n  labs (title = \"Estimated total sample size for two-sample means test\",\n        x = \"Experimental-group mean\",\n        y = \"Total sample size\") + # add labels\n        theme(plot.title = element_text(hjust = 0.5)) \n\n\n\n\nExecution in Stata\n\npower twomeans 0 (0.01 0.025 0.05 0.1 0.2), graph\n\n\n\n. power twomeans 0 (0.01 0.025 0.05 0.1 0.2), graph\n\n\n\nNow, it is easier to visualize the relationship between sample size and effect size. The sample size increases exponentially as we appraoch an effect size of zero."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Satish Bajracharya",
    "section": "",
    "text": "I am a researcher. I unravel the mysteries hidden within the vast data landscape. I ask questions and search for clues buried deep in the cryptic data sets. Armed with my laptop, my trusty companions (R and Stata), and the power of data analytics, I conjure insights to reveal the world of variables and distributions."
  },
  {
    "objectID": "blogs/welcome/index.html",
    "href": "blogs/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "This is the first post in a Quarto blog. Welcome!\n\nSince this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "blogs/Postwithplot/index.html",
    "href": "blogs/Postwithplot/index.html",
    "title": "Post With Plot",
    "section": "",
    "text": "This is a post with plot.\n\nplot(mtcars$mpg)"
  },
  {
    "objectID": "blogs/Power Calculations in RCT - Without Clusters (Theory)/index.html",
    "href": "blogs/Power Calculations in RCT - Without Clusters (Theory)/index.html",
    "title": "Power Calculations in RCT: Without Clusters (Theory)",
    "section": "",
    "text": "Introduction to power calculations\nPower calculations play a critical role in determining the number of people or households to include in a Randomized Control Trial (RCT). Further, statistical tests are prone to type 1 and type 2 errors. We can reduce the probability of such errors by increasing the sample size. However, in practice, sample size is determined by the amount of resources at hand since there is a trade off between the sample size and the cost of data collection.\nSpillovers in RCTs are also a cause of concern for researchers. As a result, we might also use clusters in RCT to tackle spillovers effects. However, clustering often requires a larger sample size as we are stratifying the sample into different clusters.\n\n\n\n\n\n\nNote\n\n\n\nClustered RCTs are more prone to type 1 and type 2 errors than an unclustered RCT design with the same number of individuals or households. The way we assign individuals to different experimental groups can also reduce the incidence of type 1 and type 2 errors. For instance, using characteristics such as gender to stratify the randomization.\n\n\nType 1 and type 2 errors\nWhen conducting RCTs, we are guided by the principle of conservatism. We do not want to promote costly policy changes without evidence. We stack the deck against ourselves by making an assumption that there is no impact made by the intervention. Given this assumption, we check whether our data is consistent with this assumption, which is called the null hypothesis. It is denoted by \\(H_0\\). While making inference, we are prone to these two types of errors which are shown below.\n\nType 1 and type 2 errors\n\nTest Statistic\n\\(H_0=T\\)\n\\(H_0=F\\)\n\n\n\n\\(t&lt;=2\\)\nCorrect Inference\nType 2 error\n\n\n\\(t&gt;=2\\)\nType 1 error\nCorrect inference\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nHere, the test statistic measures the difference in average outcomes between the treatment and control group as a result of the intervention. Type 1 error occurs when we incorrectly reject the null hypothesis \\(H_0\\) when it is actually true. Type 2 error occurs when we fail to reject the \\(H_0\\) when it is actually false.\n\n\nStatistical power\nBy understanding the type 1 and type 2 errors, we can calibrate the power of a statistical test. Power of a statistical test is the probability of rejecting a null hypothesis \\(H_0\\) when it is false. In general, it is the likelihood of not making a type 2 error. \\[Power (\\kappa): 0&lt;\\kappa&lt;1\\]\nThe level of significance determines how conservative or cautious we want to be in jumping to conclusion about the effectiveness of an intervention. The significance level determines the chance of making type 1 error. It is also referred as the size of a test denoted by \\(\\alpha\\). We would like to make sure we reject \\(H_0\\) when there is an effect. More power means we have a better chance to do so.\nWhat determines power?\n\nEffect size (\\(\\beta\\)): When running a RCT, the effect size is the difference between the average outcome of the control and treatment group. A large effect size increases the power of a statistical test.\n\nSample size (\\(n\\)): Increasing the sample size increases the power of a statistical test. Suppose we have an outcome variable \\(X\\). Variance of the estimated difference in means is related to the variance of underlying variable \\(X\\) and the sample size. As sample size increases, the variance of the estimated difference in means reduces thereby increasing power. A reduction in variance of \\(X\\) also reduces the variance of the estimated difference in means (control and treatment group).\n\nFor instance, in evaluating an education project, we can work with sample of individuals whose outcomes we expect to be relatively homogeneous. To do so, we can focus on kids in a single grade of primary school or work with a narrow age range instead of working with children in all grades.\n\n\n\n\n\n\nCaution\n\n\n\n\n\nWhat you gain in terms of power you lose in terms of external validity.\n\n\n\nThe power formula\nWhen we talk about power (\\(\\kappa\\)), we need to consider these elements:\n\nSize of a test: \\(\\alpha\\)\n\nEffect size: \\(\\beta\\) (\\(b\\) is the estimated treatment effect from the sample: \\(\\bar{X_T}-\\bar{X_C}\\), where T and C corresponds to treatment and control group)\nVariance of the underlying outcome data: \\(\\sigma^2\\)\n\nSample size: \\(n\\)\n\n\nIn practice, we fix \\(\\alpha\\), \\(n\\) and \\(\\kappa\\) given any \\(\\sigma^2\\) and reduce the five way relationship into a two way relationship between \\(\\beta\\) and \\(n\\). Doing so, we can either input an expected effect size (\\(\\beta\\)) to get the sample size (\\(n\\)) or input sample size (\\(n\\)) to get a minimum detectable effect size.\n\n\n\n\n\n\nNote\n\n\n\nThe minimum detectable effect size is the smallest effect that can be detected with a given probability by a statistical test at a certain significance level.\n\n\nThe power formula for a sample split into two groups in equal proportion in treatment and control group is: \\[\\beta=2*(z_{1-\\kappa}+z_{\\alpha/2})*\\sigma/\\sqrt n\\] Dividing both sides by \\(\\sigma\\), we get: \\[\\beta/\\sigma=2*(z_{1-\\kappa}+z_{\\alpha/2})*1/\\sqrt n\\] Here, \\(\\beta/\\sigma\\) is the minimum detectable effect size for a sample split into two groups in equal proportion.\n\n\n\n\n\n\nNote\n\n\n\nVisit this site to know more about the power formula.\n\n\nWe can invert the power formula to estimate the sample size required for a given minimum detectable effect. The formula is for two groups split into equal proportions.\n\\[n=4*(z_{1-\\kappa}+z_{\\alpha/2})^2*(\\sigma/\\beta)^2\\]\n\n\n\n\n\n\nSetting power and minimum detectable effect\n\n\n\nResearchers usually use a power size of 0.8 or higher. In many situations the minimum detectable effect is based on policy objectives or benchmark values.\n\n\nHere, we assume that the underlying variable follows a normal distribution with a known variance. But in practice, such assumption do not hold. In such cases we use a modified version of the power formula using the t statistic.\n\\[\\beta=2*(t_{1-\\kappa}+t_{\\alpha/2})*S/\\sqrt n\\]\nwhere,\n\nt statistic corresponds to the critical values of t distribution with \\(n-2\\) degrees of freedom.\nS is the square root of the estimated sample variance.\n\n\nTargeting a smaller and smaller effect size results in a sample size that rises at a steeper and steeper rate. Here, \\(1-\\beta\\) corresponds to the power of a test.\nReferences\nImpact evaluation Methods with Applications in Low- and Middle-Income Countries, World Bank"
  },
  {
    "objectID": "blogs.html",
    "href": "blogs.html",
    "title": "Blog Posts",
    "section": "",
    "text": "Comparisons Between Treatment and Control Group: Regression Analysis\n\n\n\nRCT\n\n\n\n\n\n\n\nSatish Bajracharya\n\n\nMar 12, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPower Calculations in RCT: Without Clusters (Theory)\n\n\n\nSurvey design\n\n\nRCT\n\n\n\n\n\n\n\nSatish Bajracharya\n\n\nMar 12, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPost With Plot\n\n\n\nnews\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\nHarlow Malloc\n\n\nNov 7, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nWelcome To My Blog\n\n\n\nnews\n\n\n\n\n\n\n\nTristan O’Malley\n\n\nNov 4, 2023\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "data analytics.html",
    "href": "data analytics.html",
    "title": "Data Analysis Projects",
    "section": "",
    "text": "Comparisons Between Treatment and Control Group: Regression Analysis\n\n\n\n\n\n\n\nRCT\n\n\nR\n\n\nStata\n\n\n\n\n\n\n\n\n\n\n\nMar 17, 2024\n\n\nSatish Bajracharya\n\n\n\n\n\n\n  \n\n\n\n\nPower Calculations in Unclustered RCT\n\n\n\n\n\n\n\nPower Calculations\n\n\nSurvey\n\n\nR\n\n\nStata\n\n\n\n\n\n\n\n\n\n\n\nMar 15, 2024\n\n\nSatish Bajracharya\n\n\n\n\n\n\n  \n\n\n\n\nPost With Plot\n\n\n\n\n\n\n\nnews\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\n\n\nNov 7, 2023\n\n\nHarlow Malloc\n\n\n\n\n\n\n  \n\n\n\n\nWelcome To My Blog\n\n\n\n\n\n\n\nnews\n\n\n\n\n\n\n\n\n\n\n\nNov 4, 2023\n\n\nTristan O’Malley\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/Postwithplot/index.html",
    "href": "posts/Postwithplot/index.html",
    "title": "Post With Plot",
    "section": "",
    "text": "This is a post with plot.\n\nplot(mtcars$mpg)"
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "This is the first post in a Quarto blog. Welcome!\n\nSince this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "reports/Breaking down the culture of change/index.html",
    "href": "reports/Breaking down the culture of change/index.html",
    "title": "Breaking down the culture of change",
    "section": "",
    "text": "Throughout history, change has been difficult. Breaking the shackles of normalcy and going against the well-established norm has always been a continuous struggle. Despite the presence of these antecedent conditions in history, our culture, values, and norms have continuously evolved. We have to agree that change is difficult but it is a process of making things better, not for oneself but for the betterment of the society in itself. In Adam Smith’s words, the progress of society has been made by the ingenuity of philosophers or people of speculation. In other words, change is necessary for the amelioration of human conditions and is often attributed to those who observe and speculate. However, there have been instances in history where change has deteriorated the status quo and made things worse off rather than better off. Why is it so? This again leads to the question of whether change is good or bad. We will delve into these aspects in the following sections.\nUnderstanding Individuals\nBefore understanding the culture of change, we need to understand the individuals who will bring or will be affected by the change. Borrowing from economics, the very fundamental notion of individuals is driven by wants, desires, and choices based on rationality. Although, I do not agree on rationality as sometimes we tend to make irrational decisions based on feelings and instincts…\nPlease visit the Daayitwa website to read the full article."
  },
  {
    "objectID": "posts/Power Calculations in Unclustered RCT/index.html#multiple-effect-size-calculation",
    "href": "posts/Power Calculations in Unclustered RCT/index.html#multiple-effect-size-calculation",
    "title": "Power Calculations in Unclustered RCT",
    "section": "Multiple effect size calculation",
    "text": "Multiple effect size calculation\nExecution in R\nTo calculate the sample size required for the treatment effects (0.01, 0.025, 0.05, 0.1, 0.2), we can use the for function to iterate the effect sizes and use the pwr.t.test function to calculate the corresponding sample size.\n\n# Create variable effect_sizes and assign the treatment effects\neffect_sizes &lt;- c(0.01, 0.025, 0.05, 0.1, 0.2)\n# Initialize an empty dataframe to store the results\nresult_table &lt;- data.frame()\n# Iterate over each effect size\nfor (i in effect_sizes) {\n# Calculate sample size using the pwr.t.test function\n# Make sure that the pwr package is loaded in R\nresult &lt;- pwr.t.test(n = NULL,\n                     d = i, \n                     sig.level = 0.05,\n                     power = 0.8,\n                     type = \"two.sample\")\n# n gives the sample size for each group\n# Multiply by 2 to gett the total sample size\nsample_size &lt;- result$n*2\n# Sample size for control group\nN1 &lt;- result$n\n# Sample size for treatment group\nN2 &lt;- result$n\n# Test size\nalpha &lt;- result$sig.level\n# Power\npower &lt;- result$power\n# Effect size\ndelta &lt;- result$d\n# Control group mean\nm1 &lt;- 0\n# Treatment group mean\nm2 &lt;- result$d\n# Standard deviation\nStd_dev&lt;- 1\n# Append the results to the dataframe\nresult_table &lt;- rbind(result_table,\n                      c(alpha, \n                        power,\n                        sample_size,\n                        N1, \n                        N2, \n                        delta,\n                        m1, \n                        m2, \n                        Std_dev))\n}\n# Assign column names\ncolnames(result_table) &lt;- c(\"Alpha\",\n                            \"Power\",\n                            \"Sample size\", \n                            \"N1\", \n                            \"N2\", \n                            \"Delta\", \n                            \"M1\", \n                            \"M2\", \n                            \"Std.Dev\")\n# Print the result table\nprint(result_table)\n\n  Alpha Power Sample size          N1          N2 Delta M1    M2 Std.Dev\n1  0.05   0.8 313956.3412 156978.1706 156978.1706 0.010  0 0.010       1\n2  0.05   0.8  50234.6281  25117.3140  25117.3140 0.025  0 0.025       1\n3  0.05   0.8  12560.0979   6280.0489   6280.0489 0.050  0 0.050       1\n4  0.05   0.8   3141.4661   1570.7330   1570.7330 0.100  0 0.100       1\n5  0.05   0.8    786.8114    393.4057    393.4057 0.200  0 0.200       1\n\n\nExecution in Stata\nWe again use the power twomeans command in Stata to calculate the respective sample size for the given effect size. The option table(, labels(N “Sample size” sd “Std. Dev”)) indicates that we want the output in table format, and that we want “N” to be renamed as “Sample size and sd to be renamed as”Std. Dev”.\n\npower twomeans 0 (0.01 0.025 0.05 0.1 0.2), table(, labels(N \"Sample size\" sd \"Std. Dev.\"))\n\n\n\n. power twomeans 0 (0.01 0.025 0.05 0.1 0.2), table(, labels(N \"Sample size\" sd\n&gt;  \"Std. Dev.\"))\n\nPerforming iteration Estimated sample sizes for a two-sample means test\nt test assuming sd1 = sd2 = sd\nHo: m2 = m1  versus  Ha: m2 != m1\n\n  +---------------------------------------------------------------------+\n  |   alpha   power Sample size      N1      N2   delta      m1      m2 |\n  |---------------------------------------------------------------------|\n  |     .05      .8     3.1e+05 1.6e+05 1.6e+05     .01       0     .01 |\n  |     .05      .8       50236   25118   25118    .025       0    .025 |\n  |     .05      .8       12562   6,281   6,281     .05       0     .05 |\n  |     .05      .8       3,142   1,571   1,571      .1       0      .1 |\n  |     .05      .8         788     394     394      .2       0      .2 |\n  +---------------------------------------------------------------------+\n  +-----------+\n  | Std. Dev. |\n  |-----------|\n  |         1 |\n  |         1 |\n  |         1 |\n  |         1 |\n  |         1 |\n  +-----------+\n\n\nWe can see that the required sample size increases exponentially as the effect size approaches 0. Instead of a table calculations might be easier to interpret in a graph."
  },
  {
    "objectID": "posts/Power Calculations in Unclustered RCT/index.html#plotting-the-relationship",
    "href": "posts/Power Calculations in Unclustered RCT/index.html#plotting-the-relationship",
    "title": "Power Calculations in Unclustered RCT",
    "section": "Plotting the relationship",
    "text": "Plotting the relationship\nExecution in R\n\n# Load the grammar of graphics package to plot the graph\nlibrary(ggplot2)\n# Load dplyr package to use pipe operator |&gt; to enter commands in a chain\nlibrary(dplyr)\nresult_table |&gt; # select variables Delta and Sample size from the data frame \n  select(Delta, `Sample size`) |&gt;\n  ggplot(aes( x = Delta, y = `Sample size`)) + # plot Delta on the x-axis\n  # and Sample size on the y-axis\n  geom_line(color = \"#2c3e50\", lwd = 1) + # add a geometric line to the plot \n  geom_point(color = \"#2c3e50\", size = 2) + # add a geometric point to the plot \n  labs (title = \"Estimated total sample size for two-sample means test\",\n        x = \"Experimental-group mean\",\n        y = \"Total sample size\") + # add labels\n        theme(plot.title = element_text(hjust = 0.5)) \n\n\n\n\nExecution in Stata\n\npower twomeans 0 (0.01 0.025 0.05 0.1 0.2), graph\n\n\n\n. power twomeans 0 (0.01 0.025 0.05 0.1 0.2), graph\n\n\n\nNow, it is easier to visualize the relationship between sample size and effect size. The sample size increases exponentially as we approach an effect size of zero."
  },
  {
    "objectID": "posts/Comparisons Between Treatment and Control Group - Regression Analysis/index.html",
    "href": "posts/Comparisons Between Treatment and Control Group - Regression Analysis/index.html",
    "title": "Comparisons Between Treatment and Control Group: Regression Analysis",
    "section": "",
    "text": "How to make comparisons between treatment and control group?\nWhile measuring the impact of an intervention or a program, we randomly assign individuals to treatment and control groups and compare the average outcome in each group. In general, we ask if the outcomes are different between the groups.\nResearchers use regression analysis to report the results of a RCT in scientific journals or reports.\n\n\n\n\n\n\nNote\n\n\n\nRegression equation: \\(y_i= \\alpha + \\beta T_i + \\epsilon_i\\). Here, the outcome variable is denoted by \\(y\\), error term is deonted by \\(\\epsilon_i\\), and treatment variable is denoted by \\(T_i\\). If an individual is assigned to the treatment group, \\(T = 1\\), otherwise \\(T = 0\\).\n\n\nA regression not just allows us to quantify the relationship between the treatment and outcome variable but also quantify the associations between outcomes and other variables. When we introduce other variables, we say that we are controlling for other factors.\n\\[y_i = \\alpha + \\beta T_i + \\gamma_1 Income_i + \\gamma_2 Education_i + ... \\]\nHere, we are controlling for income and education in regression equation. Introducing such controls may or may not be useful (a separate blog on control variables will be uploaded later).\nHow to measure the average impact of an intervention?\nTo measure the average impact of an intervention, we estimate the average outcome in the treatment group, \\(\\bar y (T=1)\\), and compare it with the average outcome in the control group, \\(\\bar y (T=0)\\).\nComputing average outcome for the control group and treatment group\nLets compute the average outcome for the treatment and control group. For the treatment group, the treatment variable will take on the value of one.\n\\[ \\bar y(1) = \\alpha + \\beta * 1 = \\alpha + \\beta \\] The average outcome of the treatment group is the sum of coefficients \\(\\alpha\\) and \\(\\beta\\)\nFor the control group, the treatment variable will take on the value of zero.\n\\[\\bar y(0) = \\alpha + \\beta * 0 = \\alpha\\]\nThe average outcome of the control group is \\(\\alpha\\), which is also the intercept term.\nWe can calculate the average impact of an intervention by calculating the difference in average outcome between the treatment and control group.\n\\[\\bar y(1) - \\bar y(0) = \\alpha + \\beta -\\alpha = \\beta\\]\nPopulation parameters and their estimates\nIn a regression equation, the parameter \\(\\beta\\) gives an estimate of the average impact of an intervention. We estimate the true population parameter \\(\\beta\\) from a sample in a regression analysis. Hence, we use \\(\\hat{\\beta}\\) instead of \\(\\beta\\) to denote that it is an estimate of the population parameter. We do the same for the parameter \\(\\alpha\\). Since these coefficients are estimates, the standard error is also reported in the regression output.\n\n\n\n\n\n\nStandard error\n\n\n\nThe standard error is a measure of how uncertain we are about the true underlying value of a coefficient.\n\n\nThe \\(\\beta\\) coefficient is the difference in the averages of the treatment and control group. The difference is just and estimate of the difference in the true underlying mean.\n\\[True \\space slope = \\beta \\approx Estimated \\space slope = \\hat{\\beta}\\] \\[\\beta = \\mu_1 - \\mu_0 \\approx \\hat{\\beta} = \\bar{y} (1) - \\bar{y}(0)\\] Since the coefficient \\(\\hat{\\beta}\\) is an estimate of the true underlying mean, we could form a hypothesis about true difference in mean, i.e., \\(H_0: \\mu_1 = \\mu_0\\) against \\(H_A: \\mu_1 \\neq \\mu_0\\). We can test the hypothesis about \\(\\beta\\) by forming confidence intervals around \\(\\hat{\\beta}\\) and by calculating the corresponding p values."
  },
  {
    "objectID": "blogs/Comparison Between Treatment and Control Group - Regression Analysis/index.html#decision-rules",
    "href": "blogs/Comparison Between Treatment and Control Group - Regression Analysis/index.html#decision-rules",
    "title": "Comparisons Between Treatment and Control Group: Regression Analysis",
    "section": "Decision rules",
    "text": "Decision rules\nThe \\(H_0\\) is the benchmark against which virtually all interventions are measured. The test will yield a confidence interval and a p-value.\n\n\n\n\n\n\nNote\n\n\n\nThe confidence interval gives a range of values which likely includes the true population parameter at a given confidence level.\nThe p-value is a probability that measures how compatible the data are with the null hypothesis. It is the probability of observing the data as extreme as what we observed, assuming that the \\(H_0\\) is true.\n\n\nConfidence interval\n\nIf the null value falls within the range of the confidence interval, we fail to reject the \\(H_0\\).\nIf the null value falls outside the confidence interval, we reject the \\(H_0\\).\n\n\n\n\n\n\n\nSample size and confidence interval\n\n\n\nAs the sample size increases, the confidence interval shrinks. This helps us to improve the precision of our estimates, which improves the likelihood of detecting an impact of an intervention.\n\n\nP-value\n\nIf the p-value is less than the significance level, we reject the \\(H_0\\).\nIf the p-value is more than the significance level, we fail reject the \\(H_0\\)."
  }
]