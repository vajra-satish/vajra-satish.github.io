[
  {
    "objectID": "reports/Transitioning from informality to formality - Perspectives on formalization of informal enterprises/index.html",
    "href": "reports/Transitioning from informality to formality - Perspectives on formalization of informal enterprises/index.html",
    "title": "Transitioning from informality to formality: Perspectives on formalization of informal enterprises",
    "section": "",
    "text": "Abstract: The informal economy is a common feature of developing countries and Nepal is no exception to it. Addressing the issue of heterogeneity is imperative to understanding informal enterprises, as one policy solution that works for some informal enterprises might not work for other informal enterprises. In a similar vein, the impact of the Covid-19 on informal enterprises is also an important issue that needs to be addressed. Additionally, the workers in the informal economy face rights, social protection, and representational deficits. Literature suggests three important policy implications to deal with informality: reduction of tax rates and entry costs, strict law enforcement, and improved business environment. In essence, it is crucial to understand if these policy implications are applicable in the context of Nepal. In this study, primary and secondary sources of data have been used. Inferential statistical analysis is done from the World Bank Enterprise Survey data and the World Bank Informal Survey data to make generalizations about the population of informal enterprises in Nepal. Likewise, qualitative content analysis is done from the personal interview survey data to understand enterprises from a closer perspective. The research provides some important insights on informality in the context of Nepal: a) registration depends upon important factors such as the age of the owner, sales, market speculation, business maturity, level of law enforcement, business environment, strategic behavior of competitors, and market conditions, b) the associated costs of registration is higher than its benefits, c) informal enterprises are flexible and they tend to depend on informal sources of finance, d) informal enterprises are vulnerable to external shocks like the Covid-19 pandemic. The research concludes on the need to adopt a synergistic policy approach, whereby emphasis should be laid on building a centralized database for informal workers, better access to finance, distinguished policy options for informal enterprises, information campaigns on registration procedures and benefits to registration, long-term policy on economic growth and accessible education, flexible and market-oriented training programs, identification of intermediaries, working through intermediaries to provide selective benefits and a mechanism to provide a safety net for informal workers and own-account informal workers."
  },
  {
    "objectID": "publications.html",
    "href": "publications.html",
    "title": "Satish Bajracharya",
    "section": "",
    "text": "Transitioning from informality to formality: Perspectives on formalization of informal enterprises\n\n\n\n\n\n\n\npublished report\n\n\n\n\n\n\n\n\n\n\n\nDec 22, 2021\n\n\nSatish Bajracharya, Daayitwa Nepal Public Policy Fellow\n\n\n\n\n\n\n  \n\n\n\n\nBreaking down the culture of change\n\n\n\n\n\n\n\npublished blog\n\n\n\n\n\n\n\n\n\n\n\nNov 10, 2021\n\n\nSatish Bajracharya, Daayitwa Nepal Public Policy Fellow\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/Power Calculations Using Stata - Unclustered RCT/index.html#multiple-effect-size-calculation",
    "href": "posts/Power Calculations Using Stata - Unclustered RCT/index.html#multiple-effect-size-calculation",
    "title": "Power Calculations Using Stata: Unclustered RCT",
    "section": "Multiple effect size calculation",
    "text": "Multiple effect size calculation\nExecution in R\nTo calculate the sample size required for the treatment effects (0.01, 0.025, 0.05, 0.1, 0.2), we can use the for function to iterate the effect sizes and use the pwr.t.test function to calculate the corresponding sample size.\n\n# Create variable effect_sizes and assign the treatment effects\neffect_sizes &lt;- c(0.01, 0.025, 0.05, 0.1, 0.2)\n# Initialize an empty dataframe to store the results\nresult_table &lt;- data.frame()\n# Iterate over each effect size\nfor (i in effect_sizes) {\n# Calculate sample size using the pwr.t.test function\n# Make sure that the pwr package is loaded in R\nresult &lt;- pwr.t.test(n = NULL,\n                     d = i, \n                     sig.level = 0.05,\n                     power = 0.8,\n                     type = \"two.sample\")\n# n gives the sample size for each group\n# Multiply by 2 to gett the total sample size\nsample_size &lt;- result$n*2\n# Sample size for control group\nN1 &lt;- sample_size\n# Sample size for treatment group\nN2 &lt;- sample_size\n# Test size\nalpha &lt;- result$sig.level\n# Power\npower &lt;- result$power\n# Effect size\ndelta &lt;- result$d\n# Control group mean\nm1 &lt;- 0\n# Treatment group mean\nm2 &lt;- result$d\n# Standard deviation\nStd_dev&lt;- 1\n# Append the results to the dataframe\nresult_table &lt;- rbind(result_table,\n                      c(alpha, \n                        power,\n                        sample_size,\n                        N1, \n                        N2, \n                        delta,\n                        m1, \n                        m2, \n                        Std_dev))\n}\n# Assign column names\ncolnames(result_table) &lt;- c(\"Alpha\",\n                            \"Power\",\n                            \"Sample size\", \n                            \"N1\", \n                            \"N2\", \n                            \"Delta\", \n                            \"M1\", \n                            \"M2\", \n                            \"Std.Dev\")\n# Print the result table\nprint(result_table)\n\n  Alpha Power Sample size          N1          N2 Delta M1    M2 Std.Dev\n1  0.05   0.8 313956.3412 313956.3412 313956.3412 0.010  0 0.010       1\n2  0.05   0.8  50234.6281  50234.6281  50234.6281 0.025  0 0.025       1\n3  0.05   0.8  12560.0979  12560.0979  12560.0979 0.050  0 0.050       1\n4  0.05   0.8   3141.4661   3141.4661   3141.4661 0.100  0 0.100       1\n5  0.05   0.8    786.8114    786.8114    786.8114 0.200  0 0.200       1\n\n\nExecution in Stata\nWe again use the power twomeans command in Stata to calculate the respective sample size for the given effect size. The option table(, labels(N “Sample size” sd “Std. Dev”)) indicates that we want the output in table format, and that we want “N” to be renamed as “Sample size and sd to be renamed as”Std. Dev”.\n\npower twomeans 0 (0.01 0.025 0.05 0.1 0.2), table(, labels(N \"Sample size\" sd \"Std. Dev.\"))\n\n\n\n. power twomeans 0 (0.01 0.025 0.05 0.1 0.2), table(, labels(N \"Sample size\" sd\n&gt;  \"Std. Dev.\"))\n\nPerforming iteration Estimated sample sizes for a two-sample means test\nt test assuming sd1 = sd2 = sd\nHo: m2 = m1  versus  Ha: m2 != m1\n\n  +---------------------------------------------------------------------+\n  |   alpha   power Sample size      N1      N2   delta      m1      m2 |\n  |---------------------------------------------------------------------|\n  |     .05      .8     3.1e+05 1.6e+05 1.6e+05     .01       0     .01 |\n  |     .05      .8       50236   25118   25118    .025       0    .025 |\n  |     .05      .8       12562   6,281   6,281     .05       0     .05 |\n  |     .05      .8       3,142   1,571   1,571      .1       0      .1 |\n  |     .05      .8         788     394     394      .2       0      .2 |\n  +---------------------------------------------------------------------+\n  +-----------+\n  | Std. Dev. |\n  |-----------|\n  |         1 |\n  |         1 |\n  |         1 |\n  |         1 |\n  |         1 |\n  +-----------+\n\n\nWe can see that the required sample size increases exponentially as the effect size approaches 0. Instead of a table calculations might be easier to interpret in a graph."
  },
  {
    "objectID": "posts/Power Calculations Using Stata - Unclustered RCT/index.html#plotting-the-relationship",
    "href": "posts/Power Calculations Using Stata - Unclustered RCT/index.html#plotting-the-relationship",
    "title": "Power Calculations Using Stata: Unclustered RCT",
    "section": "Plotting the relationship",
    "text": "Plotting the relationship\nExecution in R\n\n# Load the grammar of graphics package to plot the graph\nlibrary(ggplot2)\n# Load dplyr package to use pipe operator |&gt; to enter commands in a chain\nlibrary(dplyr)\nresult_table |&gt; # select variables Delta and Sample size from the data frame \n  select(Delta, `Sample size`) |&gt;\n  ggplot(aes( x = Delta, y = `Sample size`)) + # plot Delta on the x-axis\n  # and Sample size on the y-axis\n  geom_line(color = \"#2c3e50\", lwd = 1) + # add a geometric line to the plot \n  geom_point(color = \"#2c3e50\", size = 2) + # add a geometric point to the plot \n  labs (title = \"Estimated total sample size for two-sample means test\",\n        x = \"Experimental-group mean\",\n        y = \"Total sample size\") + # add labels\n        theme(plot.title = element_text(hjust = 0.5)) \n\n\n\n\nExecution in Stata\n\npower twomeans 0 (0.01 0.025 0.05 0.1 0.2), graph\n\n\n\n. power twomeans 0 (0.01 0.025 0.05 0.1 0.2), graph\n\n\n\nNow, it is easier to visualize the relationship between sample size and effect size. The sample size increases exponentially as we appraoch an effect size of zero."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Satish Bajracharya",
    "section": "",
    "text": "I am a researcher. I unravel the mysteries hidden within the vast data landscape. I ask questions and search for clues buried deep in the cryptic data sets. Armed with my laptop, my trusty companions (R and Stata), and the power of data analytics, I conjure insights to reveal the world of variables and distributions."
  },
  {
    "objectID": "blogs/welcome/index.html",
    "href": "blogs/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "This is the first post in a Quarto blog. Welcome!\n\nSince this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "blogs/Postwithplot/index.html",
    "href": "blogs/Postwithplot/index.html",
    "title": "Post With Plot",
    "section": "",
    "text": "This is a post with plot.\n\nplot(mtcars$mpg)"
  },
  {
    "objectID": "blogs/Power Calculations in RCT - Without Clusters (Theory)/index.html",
    "href": "blogs/Power Calculations in RCT - Without Clusters (Theory)/index.html",
    "title": "Power Calculations in RCT: Without Clusters (Theory)",
    "section": "",
    "text": "Introduction to power calculations\nPower calculations play a critical role in determining the number of people or households to include in a Randomized Control Trial (RCT). Further, statistical tests are prone to type 1 and type 2 errors. We can reduce the probability of such errors by increasing the sample size. However, in practice, sample size is determined by the amount of resources at hand since there is a trade off between the sample size and the cost of data collection.\nSpillovers in RCTs are also a cause of concern for researchers. As a result, we might also use clusters in RCT to tackle spillovers effects. However, clustering often requires a larger sample size as we are stratifying the sample into different clusters.\n\n\n\n\n\n\nNote\n\n\n\nClustered RCTs are more prone to type 1 and type 2 errors than an unclustered RCT design with the same number of individuals or households. The way we assign individuals to different experimental groups can also reduce the incidence of type 1 and type 2 errors. For instance, using characteristics such as gender to stratify the randomization.\n\n\nType 1 and type 2 errors\nWhen conducting RCTs, we are guided by the principle of conservatism. We do not want to promote costly policy changes without evidence. We stack the deck against ourselves by making an assumption that there is no impact made by the intervention. Given this assumption, we check whether our data is consistent with this assumption, which is called the null hypothesis. It is denoted by \\(H_0\\). While making inference, we are prone to these two types of errors which are shown below.\n\nType 1 and type 2 errors\n\nTest Statistic\n\\(H_0=T\\)\n\\(H_0=F\\)\n\n\n\n\\(t&lt;=2\\)\nCorrect Inference\nType 2 error\n\n\n\\(t&gt;=2\\)\nType 1 error\nCorrect inference\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nHere, the test statistic measures the difference in average outcomes between the treatment and control group as a result of the intervention. Type 1 error occurs when we incorrectly reject the null hypothesis \\(H_0\\) when it is actually true. Type 2 error occurs when we fail to reject the \\(H_0\\) when it is actually false.\n\n\nStatistical power\nBy understanding the type 1 and type 2 errors, we can calibrate the power of a statistical test. Power of a statistical test is the probability of rejecting a null hypothesis \\(H_0\\) when it is false. In general, it is the likelihood of not making a type 2 error. \\[Power (\\kappa): 0&lt;\\kappa&lt;1\\]\nThe level of significance determines how conservative or cautious we want to be in jumping to conclusion about the effectiveness of an intervention. The significance level determines the chance of making type 1 error. It is also referred as the size of a test denoted by \\(\\alpha\\). We would like to make sure we reject \\(H_0\\) when there is an effect. More power means we have a better chance to do so.\nWhat determines power?\n\nEffect size (\\(\\beta\\)): When running a RCT, the effect size is the difference between the average outcome of the control and treatment group. A large effect size increases the power of a statistical test.\n\nSample size (\\(n\\)): Increasing the sample size increases the power of a statistical test. Suppose we have an outcome variable \\(X\\). Variance of the estimated difference in means is related to the variance of underlying variable \\(X\\) and the sample size. As sample size increases, the variance of the estimated difference in means reduces thereby increasing power. A reduction in variance of \\(X\\) also reduces the variance of the estimated difference in means (control and treatment group).\n\nFor instance, in evaluating an education project, we can work with sample of individuals whose outcomes we expect to be relatively homogeneous. To do so, we can focus on kids in a single grade of primary school or work with a narrow age range instead of working with children in all grades.\n\n\n\n\n\n\nCaution\n\n\n\n\n\nWhat you gain in terms of power you lose in terms of external validity.\n\n\n\nThe power formula\nWhen we talk about power (\\(\\kappa\\)), we need to consider these elements:\n\nSize of a test: \\(\\alpha\\)\n\nEffect size: \\(\\beta\\) (\\(b\\) is the estimated treatment effect from the sample: \\(\\bar{X_T}-\\bar{X_C}\\), where T and C corresponds to treatment and control group)\nVariance of the underlying outcome data: \\(\\sigma^2\\)\n\nSample size: \\(n\\)\n\n\nIn practice, we fix \\(\\alpha\\), \\(n\\) and \\(\\kappa\\) given any \\(\\sigma^2\\) and reduce the five way relationship into a two way relationship between \\(\\beta\\) and \\(n\\). Doing so, we can either input an expected effect size (\\(\\beta\\)) to get the sample size (\\(n\\)) or input sample size (\\(n\\)) to get a minimum detectable effect size.\n\n\n\n\n\n\nNote\n\n\n\nThe minimum detectable effect size is the smallest effect that can be detected with a given probability by a statistical test at a certain significance level.\n\n\nThe power formula for a sample split into two groups in equal proportion in treatment and control group is: \\[\\beta=2*(z_{1-\\kappa}+z_{\\alpha/2})*\\sigma/\\sqrt n\\] Dividing both sides by \\(\\sigma\\), we get: \\[\\beta/\\sigma=2*(z_{1-\\kappa}+z_{\\alpha/2})*1/\\sqrt n\\] Here, \\(\\beta/\\sigma\\) is the minimum detectable effect size for a sample split into two groups in equal proportion.\n\n\n\n\n\n\nNote\n\n\n\nVisit this site to know more about the power formula.\n\n\nWe can invert the power formula to estimate the sample size required for a given minimum detectable effect. The formula is for two groups split into equal proportions.\n\\[n=4*(z_{1-\\kappa}+z_{\\alpha/2})^2*(\\sigma/\\beta)^2\\]\n\n\n\n\n\n\nSetting power and minimum detectable effect\n\n\n\nResearchers usually use a power size of 0.8 or higher. In many situations the minimum detectable effect is based on policy objectives or benchmark values.\n\n\nHere, we assume that the underlying variable follows a normal distribution with a known variance. But in practice, such assumption do not hold. In such cases we use a modified version of the power formula using the t statistic.\n\\[\\beta=2*(t_{1-\\kappa}+t_{\\alpha/2})*S/\\sqrt n\\]\nwhere,\n\nt statistic corresponds to the critical values of t distribution with \\(n-2\\) degrees of freedom.\nS is the square root of the estimated sample variance.\n\n\nTargeting a smaller and smaller effect size results in a sample size that rises at a steeper and steeper rate. Here, \\(1-\\beta\\) corresponds to the power of a test.\nReferences\nImpact evaluation Methods with Applications in Low- and Middle-Income Countries, World Bank"
  },
  {
    "objectID": "blogs.html",
    "href": "blogs.html",
    "title": "Blog Posts",
    "section": "",
    "text": "Comparison Between Treatment and Control Group: Regression Analysis\n\n\n\nRCT\n\n\n\n\n\n\n\nSatish Bajracharya\n\n\nMar 18, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPower Calculations in RCT: Without Clusters (Theory)\n\n\n\nSurvey design\n\n\nRCT\n\n\n\n\n\n\n\nSatish Bajracharya\n\n\nMar 12, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPost With Plot\n\n\n\nnews\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\nHarlow Malloc\n\n\nNov 7, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nWelcome To My Blog\n\n\n\nnews\n\n\n\n\n\n\n\nTristan O’Malley\n\n\nNov 4, 2023\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "data analytics.html",
    "href": "data analytics.html",
    "title": "Data Analysis Projects",
    "section": "",
    "text": "Analyzing the Impact of Receiving Monetary Incentive on Decision to Learn the Result of HIV Test\n\n\n\n\n\n\n\nRCT\n\n\nR\n\n\nStata\n\n\n\n\n\n\n\n\n\n\n\nMar 18, 2024\n\n\nSatish Bajracharya\n\n\n\n\n\n\n  \n\n\n\n\nPower Calculations in Unclustered RCT\n\n\n\n\n\n\n\nPower Calculations\n\n\nSurvey\n\n\nR\n\n\nStata\n\n\n\n\n\n\n\n\n\n\n\nMar 15, 2024\n\n\nSatish Bajracharya\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/Postwithplot/index.html",
    "href": "posts/Postwithplot/index.html",
    "title": "Post With Plot",
    "section": "",
    "text": "This is a post with plot.\n\nplot(mtcars$mpg)"
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "This is the first post in a Quarto blog. Welcome!\n\nSince this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "reports/Breaking down the culture of change/index.html",
    "href": "reports/Breaking down the culture of change/index.html",
    "title": "Breaking down the culture of change",
    "section": "",
    "text": "Throughout history, change has been difficult. Breaking the shackles of normalcy and going against the well-established norm has always been a continuous struggle. Despite the presence of these antecedent conditions in history, our culture, values, and norms have continuously evolved. We have to agree that change is difficult but it is a process of making things better, not for oneself but for the betterment of the society in itself. In Adam Smith’s words, the progress of society has been made by the ingenuity of philosophers or people of speculation. In other words, change is necessary for the amelioration of human conditions and is often attributed to those who observe and speculate. However, there have been instances in history where change has deteriorated the status quo and made things worse off rather than better off. Why is it so? This again leads to the question of whether change is good or bad. We will delve into these aspects in the following sections.\nUnderstanding Individuals\nBefore understanding the culture of change, we need to understand the individuals who will bring or will be affected by the change. Borrowing from economics, the very fundamental notion of individuals is driven by wants, desires, and choices based on rationality. Although, I do not agree on rationality as sometimes we tend to make irrational decisions based on feelings and instincts…\nPlease visit the Daayitwa website to read the full article."
  },
  {
    "objectID": "posts/Power Calculations in Unclustered RCT/index.html#multiple-effect-size-calculation",
    "href": "posts/Power Calculations in Unclustered RCT/index.html#multiple-effect-size-calculation",
    "title": "Power Calculations in Unclustered RCT",
    "section": "Multiple effect size calculation",
    "text": "Multiple effect size calculation\nExecution in R\nTo calculate the sample size required for the treatment effects (0.01, 0.025, 0.05, 0.1, 0.2), we can use the for function to iterate the effect sizes and use the pwr.t.test function to calculate the corresponding sample size.\n\n# Create variable effect_sizes and assign the treatment effects\neffect_sizes &lt;- c(0.01, 0.025, 0.05, 0.1, 0.2)\n# Initialize an empty dataframe to store the results\nresult_table &lt;- data.frame()\n# Iterate over each effect size\nfor (i in effect_sizes) {\n# Calculate sample size using the pwr.t.test function\n# Make sure that the pwr package is loaded in R\nresult &lt;- pwr.t.test(n = NULL,\n                     d = i, \n                     sig.level = 0.05,\n                     power = 0.8,\n                     type = \"two.sample\")\n# n gives the sample size for each group\n# Multiply by 2 to gett the total sample size\nsample_size &lt;- result$n*2\n# Sample size for control group\nN1 &lt;- result$n\n# Sample size for treatment group\nN2 &lt;- result$n\n# Test size\nalpha &lt;- result$sig.level\n# Power\npower &lt;- result$power\n# Effect size\ndelta &lt;- result$d\n# Control group mean\nm1 &lt;- 0\n# Treatment group mean\nm2 &lt;- result$d\n# Standard deviation\nStd_dev&lt;- 1\n# Append the results to the dataframe\nresult_table &lt;- rbind(result_table,\n                      c(alpha, \n                        power,\n                        sample_size,\n                        N1, \n                        N2, \n                        delta,\n                        m1, \n                        m2, \n                        Std_dev))\n}\n# Assign column names\ncolnames(result_table) &lt;- c(\"Alpha\",\n                            \"Power\",\n                            \"Sample size\", \n                            \"N1\", \n                            \"N2\", \n                            \"Delta\", \n                            \"M1\", \n                            \"M2\", \n                            \"Std.Dev\")\n# Print the result table\nprint(result_table)\n\n  Alpha Power Sample size          N1          N2 Delta M1    M2 Std.Dev\n1  0.05   0.8 313956.3412 156978.1706 156978.1706 0.010  0 0.010       1\n2  0.05   0.8  50234.6281  25117.3140  25117.3140 0.025  0 0.025       1\n3  0.05   0.8  12560.0979   6280.0489   6280.0489 0.050  0 0.050       1\n4  0.05   0.8   3141.4661   1570.7330   1570.7330 0.100  0 0.100       1\n5  0.05   0.8    786.8114    393.4057    393.4057 0.200  0 0.200       1\n\n\nExecution in Stata\nWe again use the power twomeans command in Stata to calculate the respective sample size for the given effect size. The option table(, labels(N “Sample size” sd “Std. Dev”)) indicates that we want the output in table format, and that we want “N” to be renamed as “Sample size and sd to be renamed as”Std. Dev”.\n\npower twomeans 0 (0.01 0.025 0.05 0.1 0.2), table(, labels(N \"Sample size\" sd \"Std. Dev.\"))\n\n\n\n. power twomeans 0 (0.01 0.025 0.05 0.1 0.2), table(, labels(N \"Sample size\" sd\n&gt;  \"Std. Dev.\"))\n\nPerforming iteration Estimated sample sizes for a two-sample means test\nt test assuming sd1 = sd2 = sd\nHo: m2 = m1  versus  Ha: m2 != m1\n\n  +---------------------------------------------------------------------+\n  |   alpha   power Sample size      N1      N2   delta      m1      m2 |\n  |---------------------------------------------------------------------|\n  |     .05      .8     3.1e+05 1.6e+05 1.6e+05     .01       0     .01 |\n  |     .05      .8       50236   25118   25118    .025       0    .025 |\n  |     .05      .8       12562   6,281   6,281     .05       0     .05 |\n  |     .05      .8       3,142   1,571   1,571      .1       0      .1 |\n  |     .05      .8         788     394     394      .2       0      .2 |\n  +---------------------------------------------------------------------+\n  +-----------+\n  | Std. Dev. |\n  |-----------|\n  |         1 |\n  |         1 |\n  |         1 |\n  |         1 |\n  |         1 |\n  +-----------+\n\n\nWe can see that the required sample size increases exponentially as the effect size approaches 0. Instead of a table calculations might be easier to interpret in a graph."
  },
  {
    "objectID": "posts/Power Calculations in Unclustered RCT/index.html#plotting-the-relationship",
    "href": "posts/Power Calculations in Unclustered RCT/index.html#plotting-the-relationship",
    "title": "Power Calculations in Unclustered RCT",
    "section": "Plotting the relationship",
    "text": "Plotting the relationship\nExecution in R\n\n# Load the grammar of graphics package to plot the graph\nlibrary(ggplot2)\n# Load dplyr package to use pipe operator |&gt; to enter commands in a chain\nlibrary(dplyr)\nresult_table |&gt; # select variables Delta and Sample size from the data frame \n  select(Delta, `Sample size`) |&gt;\n  ggplot(aes( x = Delta, y = `Sample size`)) + # plot Delta on the x-axis\n  # and Sample size on the y-axis\n  geom_line(color = \"#2c3e50\", lwd = 1) + # add a geometric line to the plot \n  geom_point(color = \"#2c3e50\", size = 2) + # add a geometric point to the plot \n  labs (title = \"Estimated total sample size for two-sample means test\",\n        x = \"Experimental-group mean\",\n        y = \"Total sample size\") + # add labels\n        theme(plot.title = element_text(hjust = 0.5)) \n\n\n\n\nExecution in Stata\n\npower twomeans 0 (0.01 0.025 0.05 0.1 0.2), graph\n\n\n\n. power twomeans 0 (0.01 0.025 0.05 0.1 0.2), graph\n\n\n\nNow, it is easier to visualize the relationship between sample size and effect size. The sample size increases exponentially as we approach an effect size of zero."
  },
  {
    "objectID": "posts/Comparisons Between Treatment and Control Group - Regression Analysis/index.html",
    "href": "posts/Comparisons Between Treatment and Control Group - Regression Analysis/index.html",
    "title": "Comparisons Between Treatment and Control Group: Regression Analysis",
    "section": "",
    "text": "How to make comparisons between treatment and control group?\nWhile measuring the impact of an intervention or a program, we randomly assign individuals to treatment and control groups and compare the average outcome in each group. In general, we ask if the outcomes are different between the groups.\nResearchers use regression analysis to report the results of a RCT in scientific journals or reports.\n\n\n\n\n\n\nNote\n\n\n\nRegression equation: \\(y_i= \\alpha + \\beta T_i + \\epsilon_i\\). Here, the outcome variable is denoted by \\(y\\), error term is deonted by \\(\\epsilon_i\\), and treatment variable is denoted by \\(T_i\\). If an individual is assigned to the treatment group, \\(T = 1\\), otherwise \\(T = 0\\).\n\n\nA regression not just allows us to quantify the relationship between the treatment and outcome variable but also quantify the associations between outcomes and other variables. When we introduce other variables, we say that we are controlling for other factors.\n\\[y_i = \\alpha + \\beta T_i + \\gamma_1 Income_i + \\gamma_2 Education_i + ... \\]\nHere, we are controlling for income and education in regression equation. Introducing such controls may or may not be useful (a separate blog on control variables will be uploaded later).\nHow to measure the average impact of an intervention?\nTo measure the average impact of an intervention, we estimate the average outcome in the treatment group, \\(\\bar y (T=1)\\), and compare it with the average outcome in the control group, \\(\\bar y (T=0)\\).\nComputing average outcome for the control group and treatment group\nLets compute the average outcome for the treatment and control group. For the treatment group, the treatment variable will take on the value of one.\n\\[ \\bar y(1) = \\alpha + \\beta * 1 = \\alpha + \\beta \\] The average outcome of the treatment group is the sum of coefficients \\(\\alpha\\) and \\(\\beta\\)\nFor the control group, the treatment variable will take on the value of zero.\n\\[\\bar y(0) = \\alpha + \\beta * 0 = \\alpha\\]\nThe average outcome of the control group is \\(\\alpha\\), which is also the intercept term.\nWe can calculate the average impact of an intervention by calculating the difference in average outcome between the treatment and control group.\n\\[\\bar y(1) - \\bar y(0) = \\alpha + \\beta -\\alpha = \\beta\\]\nPopulation parameters and their estimates\nIn a regression equation, the parameter \\(\\beta\\) gives an estimate of the average impact of an intervention. We estimate the true population parameter \\(\\beta\\) from a sample in a regression analysis. Hence, we use \\(\\hat{\\beta}\\) instead of \\(\\beta\\) to denote that it is an estimate of the population parameter. We do the same for the parameter \\(\\alpha\\). Since these coefficients are estimates, the standard error is also reported in the regression output.\n\n\n\n\n\n\nStandard error\n\n\n\nThe standard error is a measure of how uncertain we are about the true underlying value of a coefficient.\n\n\nThe \\(\\beta\\) coefficient is the difference in the averages of the treatment and control group. The difference is just and estimate of the difference in the true underlying mean.\n\\[True \\space slope = \\beta \\approx Estimated \\space slope = \\hat{\\beta}\\] \\[\\beta = \\mu_1 - \\mu_0 \\approx \\hat{\\beta} = \\bar{y} (1) - \\bar{y}(0)\\] Since the coefficient \\(\\hat{\\beta}\\) is an estimate of the true underlying mean, we could form a hypothesis about true difference in mean, i.e., \\(H_0: \\mu_1 = \\mu_0\\) against \\(H_A: \\mu_1 \\neq \\mu_0\\). We can test the hypothesis about \\(\\beta\\) by forming confidence intervals around \\(\\hat{\\beta}\\) and by calculating the corresponding p values."
  },
  {
    "objectID": "blogs/Comparison Between Treatment and Control Group - Regression Analysis/index.html#decision-rules",
    "href": "blogs/Comparison Between Treatment and Control Group - Regression Analysis/index.html#decision-rules",
    "title": "Comparison Between Treatment and Control Group: Regression Analysis",
    "section": "Decision rules",
    "text": "Decision rules\nThe \\(H_0\\) is the benchmark against which virtually all interventions are measured. The test will yield a confidence interval and a p-value.\n\n\n\n\n\n\nNote\n\n\n\nThe confidence interval gives a range of values which likely includes the true population parameter at a given confidence level.\nThe p-value is a probability that measures how compatible the data are with the null hypothesis. It is the probability of observing the data as extreme as what we observed, assuming that the \\(H_0\\) is true.\n\n\nConfidence interval\n\nIf the null value falls within the range of the confidence interval, we fail to reject the \\(H_0\\).\nIf the null value falls outside the confidence interval, we reject the \\(H_0\\).\n\n\n\n\n\n\n\nSample size and confidence interval\n\n\n\nIncreasing the sample size will shrink the confidence interval, which results in an improvement in the precision of our estimates. The increase in the precision improves the likelihood of detecting the impact of an intervention.\n\n\nP-value\n\nIf the p-value is less than the significance level, we reject the \\(H_0\\).\nIf the p-value is more than the significance level, we fail reject the \\(H_0\\)."
  },
  {
    "objectID": "posts/Analyzining the Impact of Monetary Incentive on Decision to Learn the Result of HIV Test/index.html",
    "href": "posts/Analyzining the Impact of Monetary Incentive on Decision to Learn the Result of HIV Test/index.html",
    "title": "Analyzing the Impact of Receiving Monetary Incentive on Decision to Learn the Result of HIV Test",
    "section": "",
    "text": "We use data from “The Demand for, and Impact of, Learning HIV Status” study in Malawi. The study uses a randomized controlled trial (RCT), where individuals were provided varying degrees of monetary incentives to learn about their HIV status after receiving an HIV Test.\nWe use the “Thornton HIV Testing Data.dta” for the analysis."
  },
  {
    "objectID": "posts/Analyzining the Impact of Monetary Incentive on Decision to Learn the Result of HIV Test/index.html#importing-and-describing-the-data",
    "href": "posts/Analyzining the Impact of Monetary Incentive on Decision to Learn the Result of HIV Test/index.html#importing-and-describing-the-data",
    "title": "Analyzing the Impact of Receiving Monetary Incentive on Decision to Learn the Result of HIV Test",
    "section": "Importing and describing the data",
    "text": "Importing and describing the data\nExecution in R\nThe data file is a Stata (.dta) file. To import the data set in R, we will need to install the Haven package in R and use the read_dta() function. Run the following code in R to install the Haven package:\ninstall.packages(\"haven\")\nNow, import the data set and check the list of variables and number of observations. When you download the data file, it comes with a readme file. Please read the readme file to learn more about the variables.\n\n\n\n\n\n\nThe str function in R\n\n\n\nThe str () function in R provides the structure of the dataset. However, we will only use the names () and dim() function here to make the content of this analysis shorter. Please check the Stata execution section to get a detailed description of the variables.\n\n\n\nlibrary(haven)\n# import the .dta file\ndata &lt;- read_dta(\"C:/Impact Evaluation/Regression Analysis/Data/Thornton HIV Testing Data.dta\")\n# List of variables\nnames(data)\n\n [1] \"site\"                \"rumphi\"              \"balaka\"             \n [4] \"villnum\"             \"m1out\"               \"m2out\"              \n [7] \"survey2004\"          \"got\"                 \"zone\"               \n[10] \"distvct\"             \"tinc\"                \"Ti\"                 \n[13] \"any\"                 \"under\"               \"over\"               \n[16] \"simaverage\"          \"age\"                 \"age2\"               \n[19] \"male\"                \"mar\"                 \"educ2004\"           \n[22] \"timeshadsex_s\"       \"hadsex12\"            \"eversex\"            \n[25] \"usecondom04\"         \"tb\"                  \"thinktreat\"         \n[28] \"a8\"                  \"land2004\"            \"T_consentsti\"       \n[31] \"T_consenthiv\"        \"T_final_trichresult\" \"T_final_result_ct\"  \n[34] \"T_final_result_gc\"   \"hiv2004\"             \"test2004\"           \n[37] \"followup_tested\"     \"followupsurvey\"      \"havesex_fo\"         \n[40] \"numsex_fo\"           \"likelihoodhiv_fo\"    \"numcond\"            \n[43] \"anycond\"             \"bought\"             \n\n# dimensions of the dataset\ndim(data)\n\n[1] 4820   44\n\n\nThere are 44 variables and 4,820 observations.\nExecution in Stata\nUse the cd command to import the dataset. The describe command provides a list of variables with their types and labels.\n\ncd \"C://Impact Evaluation\"\nuse \"Regression Analysis\\Data\\Thornton HIV Testing Data.dta\", clear \ndescribe\n\n\n\n. cd \"C://Impact Evaluation\"\nC:\\Impact Evaluation\n\n. use \"Regression Analysis\\Data\\Thornton HIV Testing Data.dta\", clear \n\n. describe\n\nContains data from Regression Analysis\\Data\\Thornton HIV Testing Data.dta\n  obs:         4,820                          \n vars:            44                          12 Mar 2008 11:10\n size:       785,660                          (_dta has notes)\n-------------------------------------------------------------------------------\n              storage   display    value\nvariable name   type    format     label      variable label\n-------------------------------------------------------------------------------\nsite            float   %9.0g                 1=Mchinji 2=Balaka 3=Rumphi\nrumphi          float   %9.0g                 Rumphi\nbalaka          float   %9.0g                 Balaka\nvillnum         double  %9.0g                 VILLNUM\nm1out           float   %9.0g                 Survey outcome in 1998\nm2out           float   %9.0g                 Survey outcome in 2001\nsurvey2004      float   %9.0g                 completed baseline survey\ngot             float   %9.0g                 Got HIV results\nzone            float   %9.0g                 VCT zone\ndistvct         float   %9.0g                 Distance in km\ntinc            float   %9.0g                 Total value of the incentive\n                                                (kwacha)\nTi              float   %9.0g                 Value of incentive (kwacha)\n                                                discrete\nany             float   %9.0g                 Received any incentive\nunder           float   %9.0g                 under 1.5 km\nover            float   %9.0g                 over 1.5 km\nsimaverage      float   %9.0g                 (mean) simaverage\nage             float   %10.0g                Age\nage2            float   %9.0g                 Age squared\nmale            float   %9.0g                 Gender\nmar             float   %9.0g                 Married at baseline\neduc2004        float   %9.0g                 Yrs of completed education\ntimeshadsex_s   byte    %8.0g                 Times per month had sex\n                                                (subsample)\nhadsex12        float   %9.0g                 Had sex in past 12 months\n                                                (baseline)\neversex         float   %9.0g                 Ever had sex at baseline\nusecondom04     float   %9.0g                 Used a condom during last year at\n                                                baseline\ntb              float   %9.0g                 HIV Test before baseline\nthinktreat      float   %9.0g                 Think there will be ARV treatment\n                                                in the future\na8              byte    %8.0g      A8         Likelihood of HIV infection\nland2004        float   %9.0g                 Owned any land at baseline\nT_consentsti    long    %8.0g      yesno      consent to sti test\nT_consenthiv    long    %8.0g      yesno      consent to hiv test\nT_final_trich~t float   %9.0g      res        final trich results\nT_final_resul~t float   %23.0g     otherres   final CT results\nT_final_resul~c float   %23.0g     otherres   final GC results\nhiv2004         float   %9.0g                 HIV results\ntest2004        float   %9.0g                 HIV test in 2004\nfollowup_tested byte    %8.0g                 Different HIV testing sample.\n                                                Drop from analysis\nfollowupsurvey  float   %9.0g                 Was interviewed at follow-up\nhavesex_fo      byte    %10.0g                Had sex between baseline and\n                                                follow-up\nnumsex_fo       byte    %10.0g                Num partners between baseline and\n                                                follow-up\nlikelihoodhiv~o int     %10.0g                Likelihood of infection at\n                                                follow-up\nnumcond         float   %9.0g                 Number of condoms purchased at\n                                                follow-up\nanycond         float   %9.0g                 Any condoms purchased at the\n                                                follow-up\nbought          float   %9.0g                 Bought condoms on own at\n                                                follow-up\n-------------------------------------------------------------------------------\nSorted by:"
  },
  {
    "objectID": "posts/Analyzining the Impact of Monetary Incentive on Decision to Learn the Result of HIV Test/index.html#regression-analysis",
    "href": "posts/Analyzining the Impact of Monetary Incentive on Decision to Learn the Result of HIV Test/index.html#regression-analysis",
    "title": "Analyzing the Impact of Receiving Monetary Incentive on Decision to Learn the Result of HIV Test",
    "section": "Regression Analysis",
    "text": "Regression Analysis\nHere, we analyze the impact of receiving any monetary incentive on the decision to receive results from study participant’s HIV test. The tinc variable records the amount of monetary incentive received (in kwacha) by the study participants. We tabulate the variable tinc to see the range of monetary incentives offered.\nExecution in R\n\nlibrary(dplyr)\n# ensure that all rows are diplayed when priting tibbles\noptions (tibble.print_max = Inf) \n# tabulate tinc\ndata |&gt; filter(!is.na(tinc))|&gt; # remove NA\n  select(tinc) |&gt; # select tinc from dataset\n  group_by(tinc) |&gt; # group by tinc\n  summarize(count=n()) |&gt; # create table with frequency \n  mutate(percent = count/sum(count)*100) |&gt; # create percent variable\n  round(digits = 2) # round the digits upto 2 decimal points\n\n# A tibble: 27 × 3\n    tinc count percent\n   &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;\n 1     0   679   23.4 \n 2    10    58    2   \n 3    20   154    5.31\n 4    30    81    2.79\n 5    40    64    2.21\n 6    50   205    7.07\n 7    60    37    1.28\n 8    70    40    1.38\n 9    80     7    0.24\n10    90     8    0.28\n11   100   492   17.0 \n12   110    14    0.48\n13   120    82    2.83\n14   130     9    0.31\n15   140    42    1.45\n16   150    43    1.48\n17   160    28    0.97\n18   170     8    0.28\n19   180     9    0.31\n20   200   431   14.9 \n21   210    36    1.24\n22   220    48    1.65\n23   230    30    1.03\n24   240     2    0.07\n25   250    68    2.34\n26   260     3    0.1 \n27   300   223    7.69\n\n\nExecution in Stata\n\ncd \"C://Impact Evaluation\"\nuse \"Regression Analysis\\Data\\Thornton HIV Testing Data.dta\", clear\ntabulate tinc\n\n\n\n. cd \"C://Impact Evaluation\"\nC:\\Impact Evaluation\n\n. use \"Regression Analysis\\Data\\Thornton HIV Testing Data.dta\", clear\n\n. tabulate tinc\n\nTotal value |\n     of the |\n  incentive |\n   (kwacha) |      Freq.     Percent        Cum.\n------------+-----------------------------------\n          0 |        679       23.41       23.41\n         10 |         58        2.00       25.41\n         20 |        154        5.31       30.71\n         30 |         81        2.79       33.51\n         40 |         64        2.21       35.71\n         50 |        205        7.07       42.78\n         60 |         37        1.28       44.05\n         70 |         40        1.38       45.43\n         80 |          7        0.24       45.67\n         90 |          8        0.28       45.95\n        100 |        492       16.96       62.91\n        110 |         14        0.48       63.39\n        120 |         82        2.83       66.22\n        130 |          9        0.31       66.53\n        140 |         42        1.45       67.98\n        150 |         43        1.48       69.46\n        160 |         28        0.97       70.42\n        170 |          8        0.28       70.70\n        180 |          9        0.31       71.01\n        200 |        431       14.86       85.87\n        210 |         36        1.24       87.11\n        220 |         48        1.65       88.76\n        230 |         30        1.03       89.80\n        240 |          2        0.07       89.87\n        250 |         68        2.34       92.21\n        260 |          3        0.10       92.31\n        300 |        223        7.69      100.00\n------------+-----------------------------------\n      Total |      2,901      100.00\n\n\nRunning the Regression\nHere, we only focus on analyzing the effect of receiving any financial incentive. Thus, we create a factor variable indicating whether the respondent has received an incentive or not. Once we create the treatment variable we run a regression to analyze the impact of receiving a financial incentive on the decision to obtain HIV results. The variable got indicates whether or not the respondent received the HIV result. In R we use the lm () function to run a regrssion. In Stata we use the regress command for the same\nExecution in R\n\ndata_1 &lt;- data |&gt;\n  filter(!is.na(tinc)) |&gt;\n  mutate(treatment = ifelse(tinc &gt; 0, 1, 0))\ndata_1$treatment &lt;- factor(data_1$treatment, \n                       levels = c(0, 1),\n                       labels = c(\"Control\", \"Treatment\"))\nreg &lt;- lm(got ~ treatment, data = data_1)\nsummary(reg)\n\n\nCall:\nlm(formula = got ~ treatment, data = data_1)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-0.7892 -0.3387  0.2108  0.2108  0.6613 \n\nCoefficients:\n                   Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)         0.33868    0.01696   19.97   &lt;2e-16 ***\ntreatmentTreatment  0.45055    0.01920   23.47   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.4232 on 2832 degrees of freedom\n  (67 observations deleted due to missingness)\nMultiple R-squared:  0.1628,    Adjusted R-squared:  0.1625 \nF-statistic: 550.8 on 1 and 2832 DF,  p-value: &lt; 2.2e-16\n\n\nExecution in Stata\n\ncd \"C://Impact Evaluation\"\nuse \"Regression Analysis\\Data\\Thornton HIV Testing Data.dta\", clear\ndrop if missing(tinc) | missing(got)\ngenerate treatment = cond(tinc&gt;0, 1, 0)\nlabel define treatment 0 \"Control\" 1 \"Treatment\"\nlabel val treatment treatment\nregress got treatment\n\n\n\n. cd \"C://Impact Evaluation\"\nC:\\Impact Evaluation\n\n. use \"Regression Analysis\\Data\\Thornton HIV Testing Data.dta\", clear\n\n. drop if missing(tinc) | missing(got)\n(1,986 observations deleted)\n\n. generate treatment = cond(tinc&gt;0, 1, 0)\n\n. label define treatment 0 \"Control\" 1 \"Treatment\"\n\n. label val treatment treatment\n\n. regress got treatment\n\n      Source |       SS           df       MS      Number of obs   =     2,834\n-------------+----------------------------------   F(1, 2832)      =    550.78\n       Model |  98.6657682         1  98.6657682   Prob &gt; F        =    0.0000\n    Residual |  507.321529     2,832  .179138958   R-squared       =    0.1628\n-------------+----------------------------------   Adj R-squared   =    0.1625\n       Total |  605.987297     2,833  .213903035   Root MSE        =    .42325\n\n------------------------------------------------------------------------------\n         got |      Coef.   Std. Err.      t    P&gt;|t|     [95% Conf. Interval]\n-------------+----------------------------------------------------------------\n   treatment |   .4505519    .019198    23.47   0.000     .4129083    .4881954\n       _cons |   .3386838   .0169571    19.97   0.000     .3054343    .3719333\n------------------------------------------------------------------------------\n\n\nThe treatment effect of receiving a financial incentive is 0.4506 or about 45 percentage points, compared to the control group average of about 34 percentage points. The treatment effect is statistically significant (has a p-value of 0.000).\nRobust Standard Errors\nWhen making comparison between the distribution of outcomes between two groups, we assume that the two groups have the same variance even though their means differed. This assumption is called the homoskedasticity assumption. However, when the variance in the treatment and control group are different the assumption of homoskedasticity is violated, i.e., the error terms are heteroskedastic. In such cases, we have to use robust standard errors to account for heteroskedasticity. The robust standard errors do not affect the estimates of the parameters in the regression. The robust standard errors tend to be larger than the unadjusted standard errors, which in turn makes the confidence interval wider.\nTo test for heteroskedasticity, we run the Breusch-Pagan / Cook-Weisberg test for heteroskedasticity. It tests the null hypothesis of homoskedasticity against the alternative hypothesis of heteroskedasticity. We need to install the lmtest package and run the bttest() function.\nExecution in R\n\nlibrary(lmtest)\n\nWarning: package 'lmtest' was built under R version 4.2.3\n\n\nLoading required package: zoo\n\n\nWarning: package 'zoo' was built under R version 4.2.2\n\n\n\nAttaching package: 'zoo'\n\n\nThe following objects are masked from 'package:base':\n\n    as.Date, as.Date.numeric\n\nbptest(reg, studentize = FALSE) \n\n\n    Breusch-Pagan test\n\ndata:  reg\nBP = 25.191, df = 1, p-value = 5.193e-07\n\n\nExecution in Stata\nWe use the estat hettest command in Stata to test ko heteroskedasticity.\n\ncd \"C://Impact Evaluation\"\nuse \"Regression Analysis\\Data\\Thornton HIV Testing Data.dta\", clear\ndrop if missing(tinc) | missing(got)\ngenerate treatment = cond(tinc&gt;0, 1, 0)\nlabel define treatment 0 \"Control\" 1 \"Treatment\"\nlabel val treatment treatment\nregress got treatment\nestat hettest\n\n\n\n. cd \"C://Impact Evaluation\"\nC:\\Impact Evaluation\n\n. use \"Regression Analysis\\Data\\Thornton HIV Testing Data.dta\", clear\n\n. drop if missing(tinc) | missing(got)\n(1,986 observations deleted)\n\n. generate treatment = cond(tinc&gt;0, 1, 0)\n\n. label define treatment 0 \"Control\" 1 \"Treatment\"\n\n. label val treatment treatment\n\n. regress got treatment\n\n      Source |       SS           df       MS      Number of obs   =     2,834\n-------------+----------------------------------   F(1, 2832)      =    550.78\n       Model |  98.6657682         1  98.6657682   Prob &gt; F        =    0.0000\n    Residual |  507.321529     2,832  .179138958   R-squared       =    0.1628\n-------------+----------------------------------   Adj R-squared   =    0.1625\n       Total |  605.987297     2,833  .213903035   Root MSE        =    .42325\n\n------------------------------------------------------------------------------\n         got |      Coef.   Std. Err.      t    P&gt;|t|     [95% Conf. Interval]\n-------------+----------------------------------------------------------------\n   treatment |   .4505519    .019198    23.47   0.000     .4129083    .4881954\n       _cons |   .3386838   .0169571    19.97   0.000     .3054343    .3719333\n------------------------------------------------------------------------------\n\n. estat hettest\n\nBreusch-Pagan / Cook-Weisberg test for heteroskedasticity \n         Ho: Constant variance\n         Variables: fitted values of got\n\n         chi2(1)      =    25.19\n         Prob &gt; chi2  =   0.0000\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe Breusch-Pagan test may not capture heteroskedasticity in all instances.\n\n\nThe low p-value suggests that we can reject the null hypothesis of homoskedasticity. In this case, it is better to use robust standard errors instead of unadjusted standard errors in our regression.\nRunning Regression with Robust Standard Errors\nTo use robust standard errors, we need to install the sandwich package and use vcovHC function in the coeftest() function from the lmtest package. We use a simple White standard error.\n\nlibrary(sandwich)\n\nWarning: package 'sandwich' was built under R version 4.2.3\n\ncoeftest(reg, vcov = vcovHC(reg, type = \"HC0\"))\n\n\nt test of coefficients:\n\n                   Estimate Std. Error t value  Pr(&gt;|t|)    \n(Intercept)        0.338684   0.018961  17.862 &lt; 2.2e-16 ***\ntreatmentTreatment 0.450552   0.020851  21.609 &lt; 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nExecution in Stata\nTo run a regression with robust standard errors, we run the regress command with the robust option.\n\ncd \"C://Impact Evaluation\"\nuse \"Regression Analysis\\Data\\Thornton HIV Testing Data.dta\", clear\ndrop if missing(tinc) | missing(got)\ngenerate treatment = cond(tinc&gt;0, 1, 0)\nlabel define treatment 0 \"Control\" 1 \"Treatment\"\nlabel val treatment treatment\nregress got treatment, robust\n\n\n\n. cd \"C://Impact Evaluation\"\nC:\\Impact Evaluation\n\n. use \"Regression Analysis\\Data\\Thornton HIV Testing Data.dta\", clear\n\n. drop if missing(tinc) | missing(got)\n(1,986 observations deleted)\n\n. generate treatment = cond(tinc&gt;0, 1, 0)\n\n. label define treatment 0 \"Control\" 1 \"Treatment\"\n\n. label val treatment treatment\n\n. regress got treatment, robust\n\nLinear regression                               Number of obs     =      2,834\n                                                F(1, 2832)        =     466.60\n                                                Prob &gt; F          =     0.0000\n                                                R-squared         =     0.1628\n                                                Root MSE          =     .42325\n\n------------------------------------------------------------------------------\n             |               Robust\n         got |      Coef.   Std. Err.      t    P&gt;|t|     [95% Conf. Interval]\n-------------+----------------------------------------------------------------\n   treatment |   .4505519    .020858    21.60   0.000     .4096535    .4914502\n       _cons |   .3386838   .0189675    17.86   0.000     .3014922    .3758754\n------------------------------------------------------------------------------"
  }
]